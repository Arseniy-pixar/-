Анализ алгоритма: Сортировка выбором (Selection Sort)

· Определение:
  
  · Это неадаптивный алгоритм сортировки, который последовательно сканирует неотсортированную часть массива, находит глобальный минимум (или максимум) на каждом проходе и помещает его в правильную позицию, обменивая с элементом на текущей позиции. Таким образом, отсортированная часть растёт слева направо.

· Анализ:

  · Механизм работы: Алгоритм разделяет массив на две виртуальные части: отсортированную (в начале) и неотсортированную (оставшаяся часть). На каждой итерации он выполняет линейный поиск минимума в неотсортированной части и производит обмен этого минимума с первым элементом неотсортированной части.
  
  · Циклы: Внешний цикл выполняется n-1 раз, так как последний элемент автоматически займёт своё место. Внутренний цикл на i-ой итерации выполняет n-i-1 сравнений для поиска минимума.
  
  · Количество операций: Общее число сравнений постоянно и равно (n-1)/2. Количество обменов минимально и равно n-1, что является преимуществом, если обмены дороги.

· Временная сложность: O(n²)

· Обоснование O(n²): Наличие двух вложенных циклов, каждый из которых в худшем, среднем и лучшем случае зависит от n, приводит к квадратичному росту количества операций. Алгоритм не адаптируется к исходной упорядоченности данных.

---

Анализ алгоритма: Сортировка пузырьком (Bubble Sort)

· Определение:
  
  · Это простой адаптивный алгоритм, который многократно проходит по массиву, сравнивая соседние элементы и меняя их местами, если они находятся в неправильном порядке. Процесс повторяется до тех пор, пока массив не будет полностью отсортирован.

· Анализ:

  · Механизм работы: На каждом проходе самый большой элемент из неотсортированной части "всплывает" к своему конечному положению, как пузырёк. Это достигается за счёт попарных сравнений и обменов.
  
  · Циклы: Внешний цикл в наивной реализации выполняется n-1 раз. Внутренний цикл на i-ой итерации выполняет n-i-1 сравнений и потенциальных обменов.
  
  · Оптимизация: Введение флага swapped, который отслеживает, были ли обмены на проходе, позволяет завершить работу досрочно, если массив уже отсортирован. В этом случае лучший случай становится линейным.

· Временная сложность:

  · Худший случай: O(n²) — когда массив отсортирован в обратном порядке. Требуется максимальное количество сравнений и обменов.
  
  · Лучший случай: O(n) — когда массив уже отсортирован. С флагом swapped алгоритм сделает один проход и завершится.
  
  · Средний случай: O(n²) — для случайных данных требуется квадратичное время.

· Обоснование O(n²): Количество сравнений в худшем случае составляет n(n-1)/2. Алгоритм неэффективен для больших массивов из-за большого количества обменов.

---

Анализ алгоритма: Сортировка вставками (Insertion Sort)

· Определение:
  
  · Это адаптивный и стабильный алгоритм, который строит отсортированную последовательность по одному элементу за раз. Каждый новый элемент вставляется в правильную позицию внутри уже отсортированной части, сдвигая элементы при необходимости.

· Анализ:

  · Механизм работы: Алгоритм имитирует процесс сортировки карт в руке. Начинается со второго элемента, который сравнивается с элементами слева и вставляется в нужное место. Процесс повторяется для всех последующих элементов.
  
  · Циклы: Внешний цикл выполняется n-1 раз, обрабатывая каждый новый элемент. Внутренний цикл (часто while) в худшем случае может выполнить до i итераций для i-го элемента.
  
  · Адаптивность: Эффективен для почти отсортированных массивов, так как внутренний цикл выполняет мало операций.

· Временная сложность:

  · Худший случай: O(n²) — когда массив отсортирован в обратном порядке. Каждый новый элемент должен пройти через всю отсортированную часть.
  
  · Лучший случай: O(n) — когда массив уже отсортирован. Внутренний цикл не выполняется.
  
  · Средний случай: O(n²) — для случайных данных в среднем требуется сдвигать половину отсортированной части.

· Обоснование O(n²): Сумма арифметической прогрессии количества сравнений и сдвигов: 1 + 2 + ... + (n-1) = n(n-1)/2.

---
Анализ алгоритма: Сортировка слиянием (Merge Sort)

· Определение:
 
  · Это стабильный алгоритм, основанный на парадигме "разделяй и властвуй". Он рекурсивно делит массив на две половины до тех пор, пока не останутся подмассивы из одного элемента, а затем сливает их в упорядоченном порядке.

· Анализ:

  · Декомпозиция: Процесс деления массива на подмассивы продолжается до достижения базового случая (подмассив из 1 элемента), что требует O(\log n) уровней рекурсии.
  
  · Слияние: На каждом уровне рекурсии выполняется операция слияния, которая занимает O(n) времени, так как нужно обработать все n элементов на этом уровне.
  
  · Память: Требуется дополнительная память O(n) для временных массивов при слиянии.

· Временная сложность: O(n log n)

· Обоснование O(n log n): Глубина рекурсии — \log n, на каждом уровне выполняется O(n) операций. Таким образом, общая сложность — O(n \log n). Эта сложность сохраняется для всех случаев (худшего, среднего, лучшего).

---

Анализ алгоритма: Сортировка Шелла (Shell Sort)

· Определение:
  
  · Это усовершенствование сортировки вставками, которое сортирует элементы, находящиеся на определённом расстоянии (gap) друг от друга, постепенно уменьшая это расстояние. Идея в том, чтобы сначала устранить массовую неупорядоченность, делая массив более подготовленным для финальной сортировки вставками.

· Анализ:

  · Последовательности gaps: Производительность сильно зависит от выбора последовательности шагов. Популярные последовательности: последовательность Шелла (n/2, n/4, ...), последовательность Кнута (1, 4, 13, 40, ...), последовательность Седжвика.
  
  · Механизм работы: На каждом шаге с определённым gap массив разбивается на gap независимых подмассивов, и каждый из них сортируется вставками. Малые gap делают массив почти отсортированным, что эффективно для финального прохода.

· Временная сложность:

  · Зависит от последовательности:
  
    · Для последовательности Шелла: худший случай — O(n^2).
    
    · Для последовательности Кнута: худший случай — O(n^{3/2}).
    
    · Для последовательности Седжвика: худший случай — O(n^{4/3}).
  
  · На практике: Часто работает лучше, чем O(n \log n), для средних случаев.

· Обоснование: Алгоритм избегает больших сдвигов, характерных для сортировки вставками, за счёт предварительной грубой сортировки на больших расстояниях.

---

Анализ алгоритма: Быстрая сортировка (Quick Sort)

· Определение:
  
  · Это эффективный алгоритм, использующий стратегию "разделяй и властвуй". Он выбирает опорный элемент (pivot) и перераспределяет другие элементы вокруг него так, чтобы меньшие оказались слева, а большие — справа, затем рекурсивно применяется к подмассивам.

· Анализ:

  · Выбор опорного элемента: Критически важен для производительности. Варианты: первый/последний элемент, средний, медиана трёх, случайный.
  
  · Разбиение (Partition): Процедура разбиения Ломуто или Хоара. Хоара обычно эффективнее.
  
  · Рекурсия: Глубина рекурсии зависит от сбалансированности разбиения.

· Временная сложность:

  · Средний случай: O(n log n) — когда опорный элемент делит массив на примерно равные части.
  
  · Лучший случай: O(n log n) — идеально сбалансированные разбиения.
  
  · Худший случай: O(n²) — когда опорный элемент всегда является минимальным или максимальным (например, уже отсортированный массив при выборе первого элемента).

· Обоснование: В среднем случае глубина рекурсии O(\log n), а на каждом уровне выполняется O(n) работы. В худшем случае глубина O(n), а работа на уровне O(n), что даёт O(n^2).

---

Анализ алгоритма: Пирамидальная сортировка (Heap Sort)

· Определение:
 
  · Это алгоритм сортировки на основе структуры данных "двоичная куча" (обычно max-куча). Он состоит из двух основных этапов: построения кучи и последовательного извлечения максимального элемента.

· Анализ:

  · Построение кучи (build_max_heap): Выполняется за O(n) времени, хотя кажется, что должно быть O(n \log n). Это связано с тем, что большинство элементов находятся near листьям, и для них heapify работает за малое время.

· Извлечение и перестройка: После построения кучи максимальный элемент (корень) перемещается в конец массива, и куча перестраивается для оставшихся n-1 элементов. Процедура heapify для корня занимает O(\log n), и она вызывается n-1 раз.

· Временная сложность: O(n log n)

· Обоснование O(n log n): Построение кучи — O(n), а извлечение максимумов — O(n \log n). Итог: O(n) + O(n \log n) = O(n \log n). Сложность одинакова для всех случаев.

---

Анализ алгоритма: Линейный поиск (Linear Search)

· Определение:
  
  · Это простейший алгоритм поиска, который последовательно проверяет каждый элемент коллекции до тех пор, пока не найдёт искомый элемент или не проверит все элементы.

· Анализ:

  · Механизм работы: Начинается с начала массива и поочерёдно сравнивает каждый элемент с целевым значением.
  
  · Условия останова: Поиск завершается при нахождении элемента или при достижении конца массива.

· Временная сложность:

  · Худший случай: O(n) — элемент отсутствует или находится в конце.
  
  · Лучший случай: O(1) — элемент находится на первой позиции.
  
  · Средний случай: O(n) — в среднем требуется проверить  n/2  элементов.

· Обоснование O(n): В худшем случае требуется n сравнений. Алгоритм не требует предварительной сортировки.

---

Анализ алгоритма: Бинарный поиск (Binary Search)

· Определение:
 
  · Это эффективный алгоритм поиска в отсортированном массиве, который на каждом шаге уменьшает область поиска вдвое.

· Анализ:

  · Механизм работы: Сравнивает искомый элемент со средним элементом текущего интервала. Если значения не равны, отбрасывается та половина, в которой элемент заведомо отсутствует.
  
  · Предварительное условие: Массив должен быть отсортирован.

· Временная сложность: O(log n)

· Обоснование O(log n): На каждом шаге размер области поиска уменьшается в два раза. Максимальное количество шагов, необходимое для сокращения n до 1, равно log_2 n.

---

Анализ алгоритма: Интерполяционный поиск (Interpolation Search)

· Определение:
  
  · Это алгоритм поиска в отсортированном массиве, который оценивает позицию искомого элемента на основе его значения и значений на границах интервала. Предполагает равномерное распределение данных.

· Анализ:

  · Механизм работы: Вместо деления интервала пополам, вычисляет вероятную позицию элемента по формуле: pos = lo + (x - arr[lo]) * (hi - lo)/arr[hi] - arr[lo].
  
· Эффективность: Гораздо быстрее бинарного поиска при равномерном распределении.

· Временная сложность:

  · Средний случай: O(log log n) — при равномерном распределении количество шагов очень мало.
  
  · Худший случай: O(n) — при неравномерном распределении (например, экспоненциальном) вырождается в линейный поиск.

· Обоснование: В среднем константа уменьшения области поиска лучше, чем 1/2, что приводит к двойному логарифму. В худшем случае интервал уменьшается всего на один элемент за шаг.

---

Анализ алгоритма: Поиск Фибоначчи (Fibonacci Search)

· Определение:
  
  · Это алгоритм поиска в отсортированном массиве, который использует числа Фибоначчи для определения точек разделения интервала. Является вариацией бинарного поиска, минимизирующей количество сравнений.

· Анализ:

  · Механизм работы: Использует числа Фибоначчи F(k) для определения индексов сравнения. На каждом шаге алгоритм сравнивает искомый элемент с элементом в позиции F(k-1) и, в зависимости от результата, сужает интервал, обновляя числа Фибоначчи.
  
  · Преимущество: Избегает деления и умножения, используя только сложение и вычитание, что может быть полезно в некоторых системах.

· Временная сложность: O(log n)

· Обоснование O(log n): Количество итераций пропорционально индексу k самого большого числа Фибоначчи, которое меньше или равно n. Это индекс растёт логарифмически относительно n.

