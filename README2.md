Анализ алгоритма сортировки выбором (Selection Sort)
Определение:
Сортировка выбором — это алгоритм сортировки, который последовательно находит минимальный элемент в неотсортированной части массива и ставит его в начало этой части. Таким образом, после каждой итерации отсортированными оказываются первые элементы массива, а остальные остаются неподготовленными для следующей итерации.

Работа алгоритма:
Во внешней итерации цикла проходит по каждому элементу массива, предполагая, что он временно является минимальным.
Во внутренней итерации идет проверка остальных элементов массива, чтобы убедиться, действительно ли текущий элемент является минимальным. Если найдется меньший элемент, он запоминается.
После завершения внутреннего цикла минимальный элемент из текущей рассматриваемой области меняется местами с первым элементом этой области.
Повторяем пункты 1-3, двигаясь дальше по массиву, пока не отсортируем всю коллекцию.
Временная сложность:
Наилучший случай: 
O
(
n
2
)
O(n 
2
 ) — даже если массив уже отсортирован, алгоритм все равно вынужден проходить по всему массиву для подтверждения правильности расположения каждого элемента.
Средний случай: 
O
(
n
2
)
O(n 
2
 ) — для каждого элемента массива приходится искать минимум среди остающихся элементов, что даёт нам двойную вложенную структуру итераций.
Наихудший случай: 
O
(
n
2
)
O(n 
2
 ) — опять-таки, независимо от порядка элементов, потребуется полное прохождение по массиву в каждом внутреннем цикле.
Почему именно 
O
(
n
2
)
O(n 
2
 )?
Причина такого результата связана с двумя уровнями вложенного цикла:

Внешний цикл выполняется ровно 
n
n раз (от первого до последнего элемента массива).
Внутренний цикл в среднем тоже выполняет около 
n
/
2
n/2 операций на каждой итерации внешнего цикла, так как он рассматривает все последующие элементы после текущей позиции.
Итого получаем 
O
(
n
⋅
n
/
2
)
O(n⋅n/2), что упрощенно обозначается как 
O
(
n
2
)
O(n 
2
 ).

Пространственная сложность:
O
(
1
)
O(1) — сортировка осуществляется на месте, никаких дополнительных массивов не создается.


Анализ алгоритма сортировки обменом (Bubble Sort)
Определение:## Анализ алгоритма сортировки обменом (Bubble Sort)
Определение:
Сортировка обменом (bubble sort) — это простой алгоритм сортировки, который многократно проходит по списку, сравнивая смежные элементы и меняя их местами, если они находятся в неправильном порядке. Эта операция повторяется до тех пор, пока массив не будет полностью отсортирован.

Как работает алгоритм:
На первой итерации внешний цикл проходит по всем элементам массива, начиная с первого.
Внутри цикла внутренний цикл сравнивает соседние элементы. Если предыдущий элемент больше последующего, они меняются местами.
После первой итерации самый большой элемент оказывается в конце массива.
Внешний цикл продолжает работу, но теперь последняя позиция исключается из рассмотрения, так как она уже отсортирована.
Этот процесс повторяется, пока весь массив не будет отсортирован.
Временная сложность:
Наилучший случай: 
O
(
n
)
O(n) — если массив уже отсортирован, алгоритм завершится за одну полную итерацию, потому что никакие перестановки не потребуются.
Средний случай: 
O
(
n
2
)
O(n 
2
 ) — типичный случай, когда массив случайно перемешан.
Наихудший случай: 
O
(
n
2
)
O(n 
2
 ) — когда массив отсортирован в обратном порядке, каждый элемент придется сравнивать и менять местоположение с каждым следующим элементом.
Почему такая сложность?
Алгоритм построен на двойном вложенном цикле:

Внешний цикл проходит по массиву 
(
n
−
1
)
(n−1) раз.
Внутренний цикл на каждой итерации проходит по части массива, проверяя смежные элементы и выполняя обмены.
Так как внутренний цикл внутри внешнего проходит практически полные длины массива, итоговая временная сложность равна количеству сравнений и обменов, что составляет примерно 
n
(
n
−
1
)
/
2
n(n−1)/2 действий, то есть 
O
(
n
2
)
O(n 
2
 ).

Анализ алгоритма сортировки вставками (Insert Sort)
Определение:
Сортировка вставками (insertion sort) — это простой алгоритм сортировки, который напоминает способ, которым многие люди вручную сортируют карты в колоде. Идея заключается в том, чтобы последовательно брать элементы из неотсортированной части массива и вставлять их в нужную позицию в уже отсортированной части.

Работа алгоритма:
Первые один или несколько элементов считаются уже отсортированными.
Взяв очередной элемент из неотсортированной части, мы двигаемся влево по отсортированной части, находя подходящую позицию для вставки нового элемента.
Если встречены элементы, которые больше текущего, они сдвигаются вправо, освобождая место для вставки.
После вставки очередного элемента начинается обработка следующего элемента из неотсортированной части.
Временная сложность:
Лучший случай: 
O
(
n
)
O(n) — если массив уже отсортирован, то на каждой итерации новое значение сразу попадает в правильное место, обход обходится без сдвигов.
Средний случай: 
O
(
n
2
)
O(n 
2
 ) — среднее поведение соответствует общей закономерности двойной вложенности циклов.
Худший случай: 
O
(
n
2
)
O(n 
2
 ) — когда массив отсортирован в обратном порядке, каждый элемент придётся передвигать через все предшествующие элементы.
Почему такая сложность?
Алгоритм строится на двойном вложенном цикле:

Внешний цикл пробегает по каждому элементу массива.
Внутренний цикл совершает обратные движения по отсортированной части, чтобы определить правильную позицию для вставки.
Общее количество выполняемых операций пропорционально сумме арифметической прогрессии: 
1
+
2
+
3
+
…
+
(
n
−
1
)
≈
n
2
/
2
1+2+3+…+(n−1)≈n 
2
 /2, что выражается как 
O
(
n
2
)
O(n 
2
 ).


 Анализ алгоритма сортировки слиянием (Merge Sort)
Определение:
Сортировка слиянием (merge sort) — это эффективный алгоритм сортировки, использующий принцип "разделяй и властвуй". Метод основан на рекурсивном разбиении массива на две равные части, отдельной сортировке каждой части и последующем слиянии отсортированных частей в один отсортированный массив.

Как работает алгоритм:
Исходный массив делится на две равные (или приблизительно равные) части.
Каждая из полученных частей рекурсивно сортируется аналогичным способом.
Отсортированные части сливаются вместе, формируя единый отсортированный массив.
Временная сложность:
Наилучший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — достигается благодаря принципу деления массива пополам и слияния отсортированных частей.
Средний случай: 
O
(
n
log
⁡
n
)
O(nlogn) — оптимальный результат, обеспечиваемый сбалансированным деревом рекурсии.
Худший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — одинаково хороший результат даже при неблагоприятных условиях ввода.
Почему такая сложность?
Рекурсия деления: на каждом уровне рекурсии массив делится пополам, что означает, что глубина рекурсии составляет 
log
⁡
2
n
log 
2
​
 n.
Операция слияния: на каждом этапе слияния происходит сопоставление и копирование всех элементов массива, что занимает 
O
(
n
)
O(n) времени.
Общая временная сложность складывается из глубины рекурсии умноженной на операцию слияния: 
O
(
log
⁡
n
)
×
O
(
n
)
=
O
(
n
log
⁡
n
)
O(logn)×O(n)=O(nlogn).


Анализ алгоритма сортировки Шелла (Shell Sort)
Определение:
Сортировка Шелла (shell sort) — это модификация сортировки вставками, предложенная Дональдом Шеллом в 1959 году. Основная идея заключается в том, чтобы начать сортировку с удалённых друг от друга элементов массива, постепенно сокращая шаг между ними, пока наконец не применить стандартную сортировку вставками для близко расположенных элементов.

Как работает алгоритм:
Первоначально выбирается большой шаг (gap), который определяет расстояние между элементами, подлежащими сравнению.
Сравниваются и сортируются элементы, находящиеся на таком расстоянии друг от друга.
Затем шаг уменьшается, и вновь проводится сортировка уже ближе расположенных элементов.
Наконец, когда шаг достигает 1, выполняется традиционная сортировка вставками над всеми элементами массива.
Временная сложность:
Лучший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — возможно достичь хорошей производительности при удачно подобранных величинах шага.
Средний случай: зависит от используемой последовательности шагов, но в большинстве реализаций близок к 
O
(
n
1.25
)
O(n 
1.25
 ) или 
O
(
n
(
log
⁡
n
)
2
)
O(n(logn) 
2
 ).
Худший случай: теоретически возможен 
O
(
n
2
)
O(n 
2
 ), но на практике обычно лучше благодаря выбору правильной последовательности шагов.
Почему такая сложность?
Эффективность сортировки Шелла сильно зависит от выбранной последовательности шагов (gaps). Существуют разные подходы к подбору величины шага, например:

Последовательность Марченко-Приселя: начинайте с большого шага и уменьшайте его экспоненциально.
Оптимизированные варианты, такие как Hanoi sequence или Knuth's increments, улучшают среднюю производительность.
Однако при неудачной последовательности шагов (например, постоянная разность 1) алгоритм деградирует до обычного алгоритма сортировки вставками, демонстрируя квадратичную сложность



Анализ алгоритма пирамидальной сортировки (Heapsort)
Определение:
Пирамидальная сортировка (heapsort) — это эффективный алгоритм сортировки, основанный на применении двоичных куч (binary heaps). Основной идеей является преобразование массива в специальную структуру данных — бинарную кучу, после чего осуществляется систематический отбор максимального (или минимального) элемента и размещение его в нужной позиции.

Работа алгоритма:
Построение кучи: Исходный массив преобразуется в максимальную (max-) кучу, где каждый родительский элемент больше своих детей.
Извлечение максимального элемента: Максимальный элемент (находящийся в корне кучи) помещается в конец массива, а затем обновляется структура кучи, поддерживая свойство кучи.
Повторение процедуры: Действия повторяются для оставшегося массива, пока все элементы не окажутся отсортированы.
Временная сложность:
Наилучший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — даже в наилучшем случае требуется перестроение кучи и выполнение определённого числа операций.
Средний случай: 
O
(
n
log
⁡
n
)
O(nlogn) — оптимальное время достигается благодаря логарифмической высоте кучи.
Худший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — аналогичный результат даже при неблагоприятном расположении элементов.
Почему такая сложность?
Построение кучи из массива занимает 
O
(
n
)
O(n) времени.
Каждый шаг извлечения элемента из кучи включает восстановление свойств кучи, что требует 
O
(
log
⁡
n
)
O(logn) операций.
Всего извлечений делается 
n
n раз, следовательно, общая временная сложность равна 
O
(
n
log
⁡
n
)
O(nlogn)


Анализ алгоритма быстрой сортировки (Quicksort)
Определение:
Быстрая сортировка (quicksort) — это эффективный алгоритм сортировки, реализующий стратегию "разделяй и властвуй". Основана на идее выбора опорного элемента («pivota»), вокруг которого массив делится на две части: элементы, меньшие опорного, и элементы, большие или равные ему. Затем этот процесс рекурсивно повторяется для каждой части массива.

Работа алгоритма:
Выбирается опорный элемент: это может быть любой элемент массива, обычно берут последний элемент.
Переупорядочиваются элементы: все элементы, меньшие опорного, отправляются в левую часть массива, а большие — в правую.
Рекурсивно обрабатываются обе части: процедура повторяется для левой и правой частей массива.
Процесс заканчивается, когда размеры подмассивов достигают единицы или нуля.
Временная сложность:
Наилучший случай: 
O
(
n
log
⁡
n
)
O(nlogn) — достигается, если каждый раз опорный элемент делит массив примерно пополам.
Средний случай: 
O
(
n
log
⁡
n
)
O(nlogn) — статистически ожидаемое время выполнения.
Худший случай: 
O
(
n
2
)
O(n 
2
 ) — возникает, если опорный элемент постоянно оказывается экстремально малым или большим, приводя к неравноценному делению массива.
Почему такая сложность?
Оптимальность обеспечивается за счёт принципа "разделяй и властвуй": на каждом уровне рекурсии массив делится примерно пополам, что приводит к логарифмическому числу уровней рекурсии.
Худший случай возникает, когда массив делится однобоко (например, если выбрать всегда минимальный или максимальный элемент в качестве опорного), приводя к полному просмотру массива на каждом уровне рекурсии



Анализ алгоритма линейного поиска (Linear Search)
Определение:
Линейный поиск (linear search) — это простой алгоритм поиска элемента в массиве или списке. Он последовательно проверяет каждый элемент коллекции, начиная с первого, пока не найдет искомое значение или не исчерпает все элементы.

Как работает алгоритм:
Проходим по массиву, начиная с первого элемента.
Сравниваем текущий элемент с искомым значением.
Если элемент совпал, прекращаем поиск и возвращаем его индекс.
Если дошли до конца массива и не нашли элемент, сообщаем, что элемент отсутствует.
Временная сложность:
Наилучший случай: 
O
(
1
)
O(1) — если искомый элемент находится в самом начале массива.
Средний случай: 
O
(
n
)
O(n) — предполагается, что элемент находится примерно в середине массива.
Наихудший случай: 
O
(
n
)
O(n) — если элемент находится в конце массива или вообще отсутствует.
Почему такая сложность?
Каждый элемент массива рассматривается по одному разу, и единственным действием является проверка соответствия элемента с искомым значением. Поскольку необходимо проверить каждый элемент, сложность прямо пропорциональна размеру массива, отсюда получается 
O
(
n
)
O(n)



Анализ алгоритма бинарного поиска (Binary Search)
Определение:
Бинарный поиск (binary search) — это эффективный алгоритм поиска элемента в отсортированном массиве или списке. Основан на методе исключения, где на каждом шаге диапазон поиска сокращается вдвое, за счет анализа середины диапазона.

Как работает алгоритм:
Устанавливаем границы поиска (нижнюю и верхнюю).
Рассчитываем средний индекс между границами.
Сравниваем элемент в средней точке с искомым значением:
Если средние элементы совпадают, поиск успешен.
Если средний элемент больше искомого, уточняем верхнюю границу.
Если средний элемент меньше искомого, уточняем нижнюю границу.
Повторяем шаги 2-3, пока не найдём элемент или пока диапазон поиска не сократится до пустоты.
Временная сложность:
Наилучший случай: 
O
(
1
)
O(1) — если элемент находится в центре массива.
Средний случай: 
O
(
log
⁡
n
)
O(logn) — алгоритм делит диапазон поиска пополам на каждом шаге.
Худший случай: 
O
(
log
⁡
n
)
O(logn) — поиск проходит до конца, если элемент расположен на краю массива или отсутствует.
Почему такая сложность?
Каждое обращение к массиву уменьшает диапазон поиска вдвое. За 
log
⁡
2
n
log 
2
​
 n шагов массив сжимается до единственного элемента, обеспечивая такую низкую временную сложность.



 Анализ алгоритма интерполирующего поиска (Interpolation Search)
Определение:
Интерполирующий поиск (interpolation search) — это расширенный вариант бинарного поиска, предназначенный для ускоренного поиска в больших отсортированных массивах, содержащих числовые данные, равномерно распределенные по значению. В отличие от бинарного поиска, который делит массив на две равные части, интерполирующий поиск пытается угадать лучшее место возможного нахождения элемента, исходя из текущих граничных значений.

Как работает алгоритм:
Находится приблизительная позиция искомого элемента в массиве, используя формулу интерполяции:
pivot
=
lower_bound
+
(
upper_bound
−
lower_bound
)
×
(
x
−
array
[
lower_bound
]
(
array
[
upper_bound
]
−
array
[
lower_bound
]
)
,
pivot=lower_bound+ 
(array[upper_bound]−array[lower_bound])
(upper_bound−lower_bound)×(x−array[lower_bound]
​
 ,
где:
x
x — искомое значение.
lower_bound
lower_bound, 
upper_bound
upper_bound — соответственно нижний и верхний индексы текущей области поиска.
Если значение в найденной позиции равно искомому, поиск успешно завершается.
Если значение больше искомого, верхняя граница снижается.
Если значение меньше искомого, нижняя граница повышается.
Повторяем шаги 1-4, пока не найдем элемент или пока область поиска не сузится до пустой.
Временная сложность:
Наилучший случай: 
O
(
log
⁡
log
⁡
n
)
O(loglogn) — когда данные распределены равномерно, поиск сходится очень быстро.
Средний случай: 
O
(
log
⁡
n
)
O(logn) — обычное ожидание при условии равномерного распределения данных.
Худший случай: 
O
(
n
)
O(n) — возникает, если данные распределены неравномерно или содержат одинаковые элементы подряд, что превращает алгоритм в линейный поиск.
Почему такая сложность?
Формула интерполяции позволяет намного точнее предугадывать возможное местонахождение элемента, если данные равномерно распределены. Это снижает количество необходимых проверок, давая возможность сократить время поиска до логарифмического. Но при плохой организации данных (например, дублировании элементов или резких скачках значений) точность интерполяции падает, что увеличивает количество попыток и ухудшает производительность вплоть до линейного роста.




Анализ алгоритма поиска по Фибоначчи (Fibonacci Search)
Определение:
Поиск по Фибоначчи (fibonacci search) — это разновидность бинарного поиска, предназначенная для поиска элемента в отсортированном массиве. Отличительной особенностью этого алгоритма является использование чисел Фибоначчи для определения позиций, в которых происходит разделение массива на части. Вместо деления массива точно пополам, как в обычном бинарном поиске, здесь рассматриваются пропорции золотого сечения, соответствующие числам Фибоначчи.

Как работает алгоритм:
Вычисляются три последовательных числа Фибоначчи, одно из которых превышает размер массива.
Используется второе число Фибоначчи для определения начальной позиции в массиве, откуда начнется поиск.
Если искомый элемент меньше элемента в текущей позиции, обновляется верхняя граница поиска.
Если искомый элемент больше, обновляется нижняя граница.
Процесс повторяется, уменьшая масштаб поиска с помощью чисел Фибоначчи, пока не будет найден элемент или не останется больше областей для поиска.
Временная сложность:
Наилучший случай: 
O
(
log
⁡
ϕ
n
)
O(log 
ϕ
​
 n) — алгоритм заканчивает поиск, когда элемент найден, причем сокращение области поиска происходит быстрее, чем в бинарном поиске.
Средний случай: 
O
(
log
⁡
ϕ
n
)
O(log 
ϕ
​
 n) — среднее время выполнения близко к наилучшему варианту.
Худший случай: 
O
(
log
⁡
ϕ
n
)
O(log 
ϕ
​
 n) — даже при неудачных обстоятельствах, где элемент находится в конце массива или вовсе отсутствует, алгоритм сохраняет хорошую производительность.
Здесь 
ϕ
=
1
+
5
2
≈
1.618
ϕ= 
2
1+ 
5
​
 
​
 ≈1.618 — это отношение золотого сечения.

Почему такая сложность?
Использование чисел Фибоначчи позволяет ускорить поиск, уменьшая область поиска быстрее, чем простое деление пополам, характерное для бинарного поиска. Пропорциональное уменьшение зоны поиска ведет к снижению необходимого количества итераций и достижению лучшей временной сложности.
